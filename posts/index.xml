<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Damien Lespiau</title>
		<link>https://dlespiau.github.io/posts/</link>
		<description>Recent content in Posts on Damien Lespiau</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-GB</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Sun, 29 Jan 2017 19:45:00 +0000</lastBuildDate>
		<atom:link href="https://dlespiau.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Building and using coverage-instrumented programs with Go</title>
			<link>https://dlespiau.github.io/posts/2017-01-29-building-and-using-coverage-instrumented-programs-with-go/</link>
			<pubDate>Sun, 29 Jan 2017 19:45:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2017-01-29-building-and-using-coverage-instrumented-programs-with-go/</guid>
			<description>tl;dr&amp;nbsp;We can create coverage-instrumented binaries, run them and aggregate the coverage data from running both the program and the unit tests.
In the Go world, unit testing is tightly integrated with the go tool chain. Write some unit tests, run go test and tell anyone that will listen that you really hope to never have to deal with a build system for the rest of your life.
Since Go 1.2 (Dec.</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on"><br /><b>tl;dr</b>&nbsp;We can create coverage-instrumented binaries, run them and aggregate the coverage data from running both the program and the unit tests.<br /><div style="text-align: center;"><br /></div>In the Go world, unit testing is <a href="https://golang.org/pkg/testing/">tightly integrated</a> with the go tool chain. Write some unit tests, run <code class="command">go test</code> and tell anyone that will listen that you really hope to never have to deal with a build system for the rest of your life.<br /><br />Since Go 1.2 (Dec. 2013), <code class="command">go test</code> has supported test coverage analysis: with the <code>‑cover</code> option it will tell you how much of the code is being exercised by the unit tests.<br /><br />So far, so good.<br /><br />I've been wanting to do something slightly different for some time though. Imagine you have a command line tool. I'd like to be able to run that tool with different options and inputs, check that everything is OK (using something like <a href="https://github.com/sstephenson/bats"><code>bats</code></a>) and gather coverage data from those runs. Even better, wouldn't be neat to merge the coverage from the unit tests with the one from those program runs and have an aggregated view of the code paths exercised by both kind of testing?<br /><h2 style="text-align: left;">A word about coverage in Go</h2><div>Coverage instrumentation in Go is done by rewriting the source of an application. The <code>cover</code> tool inserts code to increment a counter at the start of each <a href="https://en.wikipedia.org/wiki/Basic_block">basic block</a>, a different counter for each basic block of course. Some metadata is kept along side each of the counters: the location of the basic block (source file, start/end line &amp; columns) and the size of the basic block (number of statements).</div><div><br /></div><div>This rewriting is done automatically by <code>go test</code> when coverage information has been asked by the user (<code>go test -x</code> to see what's happening under the hood). <code>go test</code> then generates an instrumented <a href="https://golang.org/cmd/go/#hdr-Test_packages">test binary</a> and runs it.</div><div><br /></div><div>A more detailed explanation of the cover story can be found on the <a href="https://blog.golang.org/cover">Go blog</a>.</div><div><br /></div><div>Another interesting thing is that it's possible to ask <code>go test</code> to write out a file containing the coverage information with the <code>‑coverprofile</code> option. This file starts with the <i>coverage mode</i>, which is how the coverage counters are incremented. This is one of <i>set</i>, <i>count</i> or <i>atomic&nbsp;</i>(see <a href="https://blog.golang.org/cover">blog post</a> for details). The rest of the file is the list of basic blocks of the program with their metadata, one block per line:</div><div><br /></div><pre>github.com/clearcontainers/runtime/oci.go:241.29,244.9 3 4</pre><div style="text-align: left;"><br /></div><div style="text-align: left;">This describes one piece of code from <b>oci.go</b>, composed of <b>3</b>&nbsp;statements without branches, starting at line <b>241</b>, column <b>29</b> and finishing at line <b>244</b>, column <b>9</b>. This block has been reached <b>4</b> times during the execution of the test binary.</div><h2 style="text-align: left;">Generating coverage instrumented programs</h2><div>Now, what I really want to do is to compile my program with the coverage instrumentation, not just the test binary. I also want to get the coverage data written to disk when the program finishes.<br /><br />And that's when we have to start being creative.<br /><br />We're going to use <code>go test</code> to generate that instrumented program. It's possible to define a custom <code>TestMain</code> function, an entry point of a kind, for the test package. <code>TestMain</code> is often used to setup up the test environment before running the list of unit tests. We can hack it a bit to call our <code>main</code> function and jump to running our normal program instead of the tests! I ended up with something like this:<br /><br /><script src="https://gist.github.com/dlespiau/5224ee64f1ea401c00ccc852fc13afe1.js"></script><br />The current project I'm working on is called <code>cc-runtime</code>, an <a href="https://github.com/opencontainers/runtime-spec">OCI runtime</a> spawning virtual machines. It definitely deserves its own blog post, but for now, knowing the binary name is enough. Generating a coverage instrumented <code>cc-runtime</code> binary is just a matter of invoking <code>go test</code>:<br /><br /><pre>$ go test -o cc-runtime -covermode count</pre><br />I haven't used <i>atomic</i> as this binary is really a thin wrapper around a library and doesn't use may goroutines. I'm also assuming that the use of atomic operations in every branch a "quite a bit" higher then the non-atomic addition. I don't care too much if the counter is off by a bit, as long as it's strictly positive.<br /><br />We can run this binary just as if it were built with <code>go build</code>, except it's really a test binary and we have access to the same command line arguments as we would otherwise. In particular, we can ask to output the coverage profile.<br /><br /><pre>$ ./cc-runtime -test.coverprofile=list.cov list<br />[ outputs the list of containers ]</pre><br />And let's have a look at <code>list.cov</code>. Hang on... there's a problem, nothing was generated: we din't get the usual "coverage: xx.x% of statements" at the end of a <code>go test</code> run and there's no <code>list.cov</code> in the current directory. What's going on?<br /><br /></div><div>The testing package flushes the various profiles to disk <a href="https://github.com/golang/go/blob/master/src/testing/testing.go#L1061">after</a> running all the tests. The problem is that we don't run any test here, we just call main. Fortunately enough, the API to trigger a test run is <a href="https://godoc.org/testing#Main">semi-public</a>: it's not covered by the <code>go1</code> API guarantee and has "internal only" warnings. Not. Even. Scared. Hacking up a dummy test suite and running is easy enough:<br /><br /><script src="https://gist.github.com/dlespiau/c4263820c25a2aa4a59315f55c7739a6.js"></script><br />There is still one little detail left. We need to call this <code>FlushProfiles</code> function at the end of the program and that program could very well be using <code>os.Exit</code> anywhere. I couldn't find better than having a tiny <a href="https://github.com/dlespiau/covertool/blob/master/pkg/exit/exit.go">exit package</a>&nbsp;implementing the equivalent of the libc <code>atexit()</code> function and forbid direct use of <code>os.Exit</code> in favour of <code>exit.Exit()</code>. It's even <a href="https://github.com/dlespiau/covertool/blob/master/scripts/go-no-os-exit.sh">testable</a>.</div><h2 style="text-align: left;">Putting everything together</h2><div>It's now time for a full <a href="https://github.com/dlespiau/covertool/tree/master/examples/calc">example</a>. I have a small <code>calc</code> program that can compute additions and substractions.</div><br /><pre>$ calc add 4 8<br />12</pre><br />The code isn't exactly challenging:<br /><br /><script src="https://gist.github.com/dlespiau/9f1b4fca65147a06ed7a9e59aadc73c3.js"></script><br /><div>I've written some unit-tests for the <code>add</code> function only. We're going to run <code>calc</code> itself to cover the remaining statements. But first, let's see the unit tests code with both <code>TestAdd</code> and our hacked up <code>TestMain</code> function. I've swept the hacky bits away in a <a href="https://github.com/dlespiau/covertool/blob/master/pkg/cover/cover.go"><code>cover</code></a> package.<br /><br /><script src="https://gist.github.com/dlespiau/4d4b8dc2d1e09985beac950caeed195e.js"></script><br />Let's run the unit-tests, asking to save a <code>unit-tests.cov</code> profile.<br /><br /><pre>$ go test -covermode count -coverprofile unit-tests.cov<br />PASS<br />coverage: 7.1% of statements<br />ok   github.com/dlespiau/covertool/examples/calc 0.003s</pre><br />Huh. 7.1%. Well, we're only testing the 1 statement of the <code>add</code> function after all. It's time for the magic. Let's compile an instrumented calc:<br /><br /><pre>$ go test -o calc -covermode count</pre><br />And run <code>calc</code> a few times to exercise more code paths. For each run, we'll produce a coverage profile.<br /><br /><pre>$ ./calc -test.coverprofile=sub.cov sub 1 2<br />-1<br />$ covertool report sub.cov<br />coverage: 57.1% of statements<br /><br />$ ./calc -test.coverprofile=error1.cov foo<br />expected 3 arguments, got 1<br />$ covertool report error1.cov<br />coverage: 21.4% of statements<br /><br />$ ./calc -test.coverprofile=error2.cov mul 3 4<br />unknown operation: mul<br />$ covertool report error2.cov<br />coverage: 50.0% of statements<br /></pre><br />We want to aggregate those profiles into one single super-profile. While there are <a href="https://github.com/golang/go/commit/f39050c8ebf894ccedc0b99de96f7412be97af89">some hints</a> people are interested in merging profiles from several runs (that commit is in go 1.8), the cover tool doesn't seem to support these kind of things easily so I wrote a little utility to do it: <a href="https://github.com/dlespiau/covertool"><code>covertool</code></a><br /><br /><pre>$ covertool merge -o all.cov unit-tests.cov sub.cov error1.cov error2.cov</pre><br />Unfortunately again, I discovered <a href="https://github.com/golang/go/issues/20515">a bug</a> in Go's cover and so we need <a href="https://github.com/dlespiau/covertool"><code>covertool</code></a> to tell us the coverage of the aggregated profile:<br /><br /><pre>$ covertool report all.cov<br />coverage: 92.9% of statements</pre><br />Not Bad!<br /><br />Still not 100% though. Let's fire the HTML coverage viewer to see what we are missing:<br /><br /><pre>$ go tool cover -html=all.cov</pre><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-j5ssZUYZfSE/WSxkK4m6n8I/AAAAAAAAA7M/E8dN060oMdIq9A0qpXSyJCPr7MpzwoiVQCLcB/s1600/Screenshot%2Bfrom%2B2017-05-29%2B19-06-34.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="741" data-original-width="1366" height="347" src="https://2.bp.blogspot.com/-j5ssZUYZfSE/WSxkK4m6n8I/AAAAAAAAA7M/E8dN060oMdIq9A0qpXSyJCPr7MpzwoiVQCLcB/s640/Screenshot%2Bfrom%2B2017-05-29%2B19-06-34.png" width="640" /></a></div><br />Oh, indeed, we're missing 1 statement. We never call <code>add</code> from the command line so that switch case is never covered. Good. Seems like everything is working as intended.<br /><br /></div><h2 style="text-align: left;">Here be dragons</h2><div>As fun as this is, it definitely feels like very few people are doing this kind of instrumented binaries. Everything is a bit rough around the edges. I may have missed something obvious, of course, but I'm sure the Internet will tell me if that's the case!</div><br />It'd be awesome if we could have something nicely integrated in the future.<br /><br /></div>
]]></content>
		</item>
		
		<item>
			<title>Continuous Testing with Patchwork</title>
			<link>https://dlespiau.github.io/posts/2016-02-15-continuous-testing-with-patchwork/</link>
			<pubDate>Mon, 15 Feb 2016 18:00:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2016-02-15-continuous-testing-with-patchwork/</guid>
			<description>As promised in the post introducing my recent work on Patchwork, I&#39;ve written some more in-depth documentation to explain how to hook testing to Patchwork. I&#39;ve also realized that a blog post might not be the best place to put that documentation and opted to put it in the proper manual:
http://patchwork-freedesktop.readthedocs.org/en/latest/testing.html
Happy reading! </description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on">As promised in the <a href="http://damien.lespiau.name/2016/02/augmenting-mailing-lists-with-patchwork.html">post introducing my recent work on Patchwork</a>, I've written some more in-depth documentation to explain how to hook testing to Patchwork. I've also realized that a blog post might not be the best place to put that documentation and opted to put it in the proper manual:<br /><br /><ul style="text-align: left;"><li><a href="http://patchwork-freedesktop.readthedocs.org/en/latest/testing.html">http://patchwork-freedesktop.readthedocs.org/en/latest/testing.html</a></li></ul><br />Happy reading!</div>
]]></content>
		</item>
		
		<item>
			<title>Augmenting mailing-lists with Patchwork - Another try</title>
			<link>https://dlespiau.github.io/posts/2016-02-13-augmenting-mailing-lists-with-patchwork---another-try/</link>
			<pubDate>Sat, 13 Feb 2016 15:36:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2016-02-13-augmenting-mailing-lists-with-patchwork---another-try/</guid>
			<description>The mailing-list problem
Many software projects use mailing-lists, which usually means mailman, not only for discussions around that project, but also for code contributions. A lot of open source projects work that way, including the one I interact with the most, the Linux kernel. A contributor sends patches to a mailing list, these days using&amp;nbsp;git send-email, and waits for feedback or for his/her patches to be picked up for inclusion if fortunate enough.</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on"><h3 style="text-align: left;">The mailing-list problem</h3><div><br />Many software projects use mailing-lists, which usually means <a href="https://www.gnu.org/software/mailman/">mailman</a>, not only for discussions around that project, but also for code contributions. A lot of open source projects work that way, including the one I interact with the most, the Linux kernel. A contributor sends patches to a mailing list, these days using&nbsp;<a href="https://git-scm.com/docs/git-send-email"><code class="command">git send-email</code></a>, and waits for feedback or for his/her patches to be picked up for inclusion if fortunate enough.<br /><br /><b>Problem is, mailing-lists are awful for code contribution.</b><br /><br />A few of the issues at hand:<br /><ul style="text-align: left;"><li>Dealing with patches and emails can be daunting for new contributors,</li><li>There's no feedback that someone will look into the patch at some point,</li><li>There's no tracking of which patch has been processed (eg. included into the tree). A shocking number of patches are just dropped as a direct consequence,</li><li>There's no way to add metadata to a submission. For instance, we can't assign a reviewer from a pool of people working on the project. As a result, review is only working thanks to the good will of people. It's not necessarily a bad thing, but it doesn't work in a corporate environment with deadlines,</li><li>Mailing-lists are all or nothing: one subscribes to the activity of the full project, but may only care about following the progress of a couple of patches,</li><li>There's no structure at all actually, it's all just emails,</li><li>No easy way to hook continuous integration testing,</li><li>The tools are really bad any time they need to interact with the mailing-list: try to send a patch as a reply to a review comment, addressing it. It starts with going to look at the headers of the review email to copy/paste its <a href="https://en.wikipedia.org/wiki/Message-ID">Message-ID</a>, followed by an arcane incantation:<br /><pre class="terminal">$ git send-email --to=&lt;mailing-list&gt; --cc=&lt;reviewer&gt; \<br />                 --in-reply-to=&lt;reviewer-mail-message-id&gt; \<br />                 --reroll-count 2 -1 HEAD~2</pre></li></ul><br /><h3 style="text-align: left;">Alternative to mailing-lists</h3><div><br /></div><div>Before mentioning Patchwork, it's worth saying that a project can merely decide to switch to using something else than a mailing-list to handle code contributions; To name a few: Gerrit, Phabricator, Github, Gitlab, Crucible.<br /><br />However, there can be some friction preventing the adoption those tools. People have built their own workflow around mailing-lists for years and it's somewhat difficult to adopt anything else over night. Projects can be big with no clear way to make decisions, so sticking to mailing-lists can just be the result of inertia.<br /><br />The alternatives also have problems of their own and there's no clear winner, nothing like how <code class="command">git</code> took over the world.</div><h3 style="text-align: left;"><br class="Apple-interchange-newline" />Patchwork</h3><div><br /></div>So, the path of least resistance is to keep mailing-lists. <a href="http://jk.ozlabs.org/">Jemery Kerr</a>&nbsp;had the idea to augment mailing-lists with a tool that would track the activity there and build a database of patches and their status (new, reviewed, merged, dropped, ...).&nbsp;<a href="http://jk.ozlabs.org/projects/patchwork/">Patchwork</a>&nbsp;was born.<br /><br />Here are some Patchwork instances in the wild:<br /><ul style="text-align: left;"><li>Kernel - <a href="https://patchwork.kernel.org/">https://patchwork.kernel.org/</a></li><li>Kernel and a variety of projects -&nbsp;<a href="http://patchwork.ozlabs.org/">http://patchwork.ozlabs.org/</a></li><li>OpenEmbedded - <a href="http://patchwork.openembedded.org/">http://patchwork.openembedded.org/</a></li><li>freedesktop.org projects -&nbsp;<a href="https://patchwork.freedesktop.org/">https://patchwork.freedesktop.org/</a></li></ul><div><br />The KMS and DRI Linux subsystems are using <a href="http://freedesktop.org/">freedesktop.org</a>&nbsp;to host their mailing-lists, which includes the i915 Intel driver, project I've been contributing to since 2012. We have an instance of Patchwork there, and, while somewhat useful, the tool fell short of what we really wanted to do with our code contribution process.</div><br /><h3 style="text-align: left;">Patches are welcome!</h3></div><div><br />So? it was time to do something about the situation and I started improving Patchwork to answer some of the problems outlined above. Given enough time, it's possible to help on all fronts.<br /><br />The code can be found on <a href="https://github.com/dlespiau/patchwork/">github</a>, along with the current <a href="https://github.com/dlespiau/patchwork/issues">list of issues and enhancements</a> we have thought about. I also maintain <a href="https://patchwork.freedesktop.org/">freedesktop.org's instance</a> for the graphics team at Intel, but also any freedesktop.org project that would like to give it a try.<br /><br /><br /><h3 style="text-align: left;">Design, Design, Design</h3><div><br /></div><div>First things first, we improved how Patchwork looks and feels. <a href="https://twitter.com/belenpena">Belén</a>, of <a href="http://www.openembedded.org/wiki/Main_Page">OpenEmbedded</a>/<a href="https://www.yoctoproject.org/">Yocto</a> fame, has very graciously spent some of her time to rethink how the interaction should behave.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://2.bp.blogspot.com/-PoKzI30S5dY/Vr8SEmLEI1I/AAAAAAAAAbw/Efx15zJHUn0/s1600/Screenshot%2Bfrom%2B2016-02-13%2B06-08-38.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="356" src="https://2.bp.blogspot.com/-PoKzI30S5dY/Vr8SEmLEI1I/AAAAAAAAAbw/Efx15zJHUn0/s640/Screenshot%2Bfrom%2B2016-02-13%2B06-08-38.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Before, ...</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://2.bp.blogspot.com/-7uN04ij5l9s/Vr8UzskHMII/AAAAAAAAAb8/xgRaadguHjs/s1600/Screenshot%2Bfrom%2B2016-02-13%2B06-08-59.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="358" src="https://2.bp.blogspot.com/-7uN04ij5l9s/Vr8UzskHMII/AAAAAAAAAb8/xgRaadguHjs/s640/Screenshot%2Bfrom%2B2016-02-13%2B06-08-59.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">... and after!</td></tr></tbody></table><br />There is still a lot of work remaining to roll out the new design and the new interaction model on all of Patchwork. A glimpse of what that interaction looks like so far:<br /><br /><div style="text-align: center;"><iframe allowfullscreen="" frameborder="0" height="360" src="https://www.youtube.com/embed/N8O7D11r2K8" width="640"></iframe><br /></div></div><div><br /></div><h3>Series</h3><div style="text-align: left;"><br /></div><div>One thing was clear from the start: I didn't want to have <i>Patches</i> as the main object tracked, but <i>Series</i>, a collection of patches. Typically, developing a&nbsp; new feature requires more than one patch, especially with the kernel where it's customary to write a lot of orthogonal smaller commits rather than a big (and often all over the place) one. Single isolated commits, like a small bug fix, are treated as a series of one patch.<br /><br />But that's not all. Series actually evolve over time as the developer answers review comments and the patch-set matures. Patchwork also tracks that evolution, creating several <i>Revisions</i> for the same series. <a href="https://patchwork.freedesktop.org/series/2720/">This colour management series</a> from <a href="https://twitter.com/llandwerlin">Lionel</a> shows that history tracking (beware, this is not the final design!).<br /><br />I have started documenting <a href="http://patchwork-freedesktop.readthedocs.org/en/latest/manual.html#submitting-patches">what Patchwork can understand</a>. Two ways can be used to trigger the creation of a new revision: sending a revised patch as a reply to the reviewer email or resending the full series with a similar cover letter subject.<br /><br />There are many ambiguous cases and some others cases not really handled yet, one of them being sending a series as a reply to another series. That can be quite confusing for the patch submitter but the documented flows should work.<br /><br /></div><h3 style="text-align: left;">REST API</h3><div style="text-align: left;"><br /></div><div style="text-align: left;">Next is dusting off Patchwork's XML-RPC API. I wanted to be able to use the same API from both the web pages and <code class="command">git-pw</code>, a command line client.<br /><br />This new API is close to complete enough to replace the XML-RPC one and already offers a few more features (eg. testing integration). I've also been <a href="http://patchwork-freedesktop.readthedocs.org/en/latest/rest.html">carefully documenting it</a>. </div><div style="text-align: left;"><br /></div><h3 style="text-align: left;"><a href="http://patchwork-freedesktop.readthedocs.org/en/latest/manual.html#git-pw">git-pw</a></h3></div><div><br /></div><div><a href="http://bloggingthemonkey.blogspot.co.uk/">Rob Clark</a> had been asking for years for a better integration with git from the Patchwork's command line tool, especially sharing its configuration file. There also are a number of git "plugins" that have appeared to bridge git with various tools, like <a href="http://blog.fishsoup.net/2008/11/16/git-bz-bugzilla-subcommand-for-git/">git-bz</a> or <a href="https://phabricator.freedesktop.org/diffusion/GITPHAB/">git-phab</a>.<br /><br />Patchwork has now his own <a href="http://patchwork-freedesktop.readthedocs.org/en/latest/manual.html#git-pw">git-pw</a>, using the REST API. There, again, more work is needed to be in an acceptable shape, but it can already be quite handy to, for instance, apply a full series in one go:<br /><br /><pre class="terminal">$ git pw apply -s 122<br />Applying series: DP refactoring v2 (rev 1)<br />Applying: drm/i915: Don't pass *DP around to link training functions<br />Applying: drm/i915: Split write of pattern to DP reg from intel_dp_set_link_train<br />Applying: drm/i915 Call get_adjust_train() from clock recovery and channel eq<br />Applying: drm/i915: Move register write into intel_dp_set_signal_levels()<br />Applying: drm/i915: Move generic link training code to a separate file<br />...</pre><br /></div><div><h3 style="text-align: left;"><span style="font-size: 18.72px;"><b>Testing Integration</b></span></h3></div><div><span style="font-size: 18.72px;"><br class="Apple-interchange-newline" /></span> <br />This is what kept my busy the last couple of months: How to integrate patches sent to a mailing-list with Continuous Integration systems. The flow I came up with is not very complicated but a picture always helps:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-IZr4mrSiyWk/Vr8_KQeZfmI/AAAAAAAAAcM/lfj2_mpEd2U/s1600/testing-ci-flow.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="422" src="https://1.bp.blogspot.com/-IZr4mrSiyWk/Vr8_KQeZfmI/AAAAAAAAAcM/lfj2_mpEd2U/s640/testing-ci-flow.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Hooking tests to Patchwork</td></tr></tbody></table><br /><br />Patchwork is exposing an API so mailing-lists are completely abstracted from systems using that API. Both retrieving the series/patches to test and sending back test results is done through HTTP. That makes testing systems fairly easy to write.<br /><br /><a href="https://www.linkedin.com/in/tomi-sarvela-b729b31b">Tomi Sarvela</a> hooked our test-suite, <a href="https://cgit.freedesktop.org/xorg/app/intel-gpu-tools/">intel-gpu-tools</a>, to patches sent to <a href="https://lists.freedesktop.org/mailman/listinfo/intel-gfx">intel-gfx</a> and we're now gating patch acceptance to the kernel driver with the result of that testing.<br /><br />Of course, it's not that easy. In our case, we've accumulated some technical debt in both the driver and the test suite, which means it will take time to beat both into be a fully reliable go/no-go signal. People have been actively looking at improving the situation though (thanks!) and I have hope we can reach that reliability sooner rather than later.<br /><br />As a few words of caution about the above, I'd like to remind everyone that the devil always is in the details:<br /><ul style="text-align: left;"><li>We've restricted the automated testing to a subset of the tests we have (Basic Acceptance Tests aka BATs) to provide a quick answer to developers, but also because some of our tests aren't well bounded,</li><li>We have no idea how much code coverage that subset really exercises, playing with the kernel gcov support would be interesting for sure,</li><li>We definitely don't deal with the variety of display sinks (panels and monitors) that are present in the wild.</li></ul>This means we won't catch all the i915 regressions. Time will definitely improve things as we connect more devices to the testing system and fix our tests and driver.</div><div><br /></div><div>Anyway, let's leave i915 specific details for another time. A last thing about this testing integration is that Patchwork can be configured to send emails back to the submitter/mailing-list with some test results. As an example, I've written <a href="https://github.com/dlespiau/jenkins-patchwork-checkpatch.pl/blob/master/test-checkpatch.py">a checkpatch.pl integration</a> that will <a href="https://lists.freedesktop.org/archives/intel-gfx/2015-December/083414.html">tell people to fix their patches</a> without the need of a reviewer to do it. I know, living in the future.</div><div><br /></div><div>For more in-depth documentation about continuous testing with Patchwork, see <a href="http://patchwork-freedesktop.readthedocs.org/en/next/testing.html">the testing section of the manual</a>.</div><div><br /></div><div><h3 style="text-align: left;"><span style="font-size: 18.72px;"><span style="font-size: 18.72px; font-weight: bold;">What's next?</span></span></h3><br />This blog post is long enough as is, let's finish by the list of things I'd like to be in a acceptable state before I'll happily tag a first version:<br /><ul style="text-align: left;"><li>Series support without without known bugs</li><li>REST API and git pw able to replace XML-RPC and pwclient</li><li>Series, Patches and Bundles web pages ported to the REST API and the new filter/action interaction.</li><li>CI integration</li><li>Patch and Series life cycle redesigned with more automatic state  changes (ie. when someone gives a reviewed-by tag, the patch state  should change to reviewed)</li></ul></div><div style="text-align: left;">There are plenty of other exciting ideas captured in <a href="https://github.com/dlespiau/patchwork/issues">the github issues</a> for when this is done.</div><div><span style="font-size: 18.72px;"><span style="font-size: 18.72px; font-weight: bold;"><br /></span></span></div><h3 style="text-align: left;"><b style="font-size: 18.72px;">Links</b></h3><div><ul style="text-align: left;"><li><a href="https://github.com/dlespiau/patchwork">Github</a></li><li><a href="http://patchwork-freedesktop.readthedocs.org/en/latest/">Documentation</a></li><li><a href="https://bugs.freedesktop.org/enter_bug.cgi?product=freedesktop.org">freedesktop.org Patchwork support</a> (choose the Patchwork component)&nbsp;</li></ul></div><div><span style="font-size: 18.72px;"><b><br /></b></span></div><div><br /></div><div><br /></div></div>
]]></content>
		</item>
		
		<item>
			<title>Testing for pending migrations in Django</title>
			<link>https://dlespiau.github.io/posts/2016-01-03-testing-for-pending-migrations-in-django/</link>
			<pubDate>Sun, 03 Jan 2016 18:09:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2016-01-03-testing-for-pending-migrations-in-django/</guid>
			<description>DB migration support has been added in Django 1.7+, superseding South. More specifically, it&#39;s possible to automatically generate migrations steps when one or more changes in the application models are detected. Definitely a nice feature!
I&#39;ve written a small generic unit-test that one should be able to drop into the tests directory of any Django project and that checks there&#39;s no pending migrations, ie. if the models are correctly in sync with the migrations declared in the application.</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on"><div dir="ltr" style="text-align: left;" trbidi="on">DB migration support has been added in Django 1.7+, superseding <a href="http://django-south.readthedocs.io/en/latest/">South</a>. More specifically, it's possible to automatically generate migrations steps when one or more changes in the application models are detected. Definitely a nice feature!<br /><br />I've written a small generic unit-test that one should be able to drop into the tests directory of any Django project and that checks there's no pending migrations, ie. if the models are correctly in sync with the migrations declared in the application. Handy to check nobody has forgotten to <code class="command">git add</code> the migration file or that an innocent looking change in <code class="filename">models.py</code> doesn't need a migration step generated. Enjoy!<br /><br /><a href="https://djangosnippets.org/snippets/10567/">See the code on djangosnippets</a>&nbsp;or as a <a href="https://gist.github.com/dlespiau/a3fb10421d68be2a59daebf15f8b781e">github gist</a>!</div><script src="https://gist.github.com/dlespiau/a3fb10421d68be2a59daebf15f8b781e.js"></script><br /></div>
]]></content>
		</item>
		
		<item>
			<title>Working in a separate prefix</title>
			<link>https://dlespiau.github.io/posts/2014-12-05-working-in-a-separate-prefix/</link>
			<pubDate>Fri, 05 Dec 2014 18:00:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2014-12-05-working-in-a-separate-prefix/</guid>
			<description>I&#39;ve been surprised in the past to discover that even some seasoned engineers didn&#39;t know how to use the autotools prefix feature. A sign they&#39;ve been lucky enough and didn&#39;t have to deal with Autotools too much. Here&#39;s my attempt to provide some introduction to ./configure --prefix.
Working with or in &#34;a separate prefix&#34; is working with libraries and binaries (well, anything produced by &#39;make install&#39; in an autotooled project really) installed in a different directory than the system-wide ones (/usr or even /usr/local that can become quite messy).</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on">I've been surprised in the past to discover that even some seasoned engineers didn't know how to use the autotools prefix feature. A sign they've been lucky enough and didn't have to deal with Autotools too much. Here's my attempt to provide some introduction to <code>./configure --prefix</code>.<br /><br />Working with or in "a separate prefix" is working with libraries and binaries (well, anything produced by '<code>make install</code>' in an autotooled project really) installed in a different directory than the system-wide ones (/usr or even /usr/local that can become quite messy). It is the preferred way to hack on a full stack without polluting your base distribution and has several advantages:<br /><ul><li>One&nbsp;can hack on the whole stack without the fear of not being able to run your desktop environment you're working with if something goes wrong,</li><li>More often than not, one needs a relatively recent library that your distribution doesn't ship with (say a recent libdrm). When working with the dependencies in a prefix, it's just a matter of recompiling it.</li></ul><br />Let's take an example to make the discussion easier:<br /><ul style="text-align: left;"><li>&nbsp;We want to compile libdrm and intel-gpu-tools (because intel-gpu-needs needs a more recent libdrm than the one coming with your distribution),</li><li>&nbsp;We want to use the <code>~/gfx</code> directory for our work,</li><li>git trees with be cloned in <code>~/gfx/sources</code>,</li><li><code>~/gfx/install</code> is chosen as the prefix.</li></ul><br />First, let's clone the needed git repositories:<br /><pre class="brush: bash; gutter: false">$ mkdir -p ~/gfx/sources ~/gfx/install<br />$ cd ~/gfx/sources<br />$ git clone git://anongit.freedesktop.org/mesa/drm libdrm<br />$ git clone git://anongit.freedesktop.org/xorg/app/intel-gpu-tools</pre>Then you need to source a script that will set-up your environment with a few variables to tell the system to use the prefix (both at run-time and compile-time). A minimal version of that script for our example is (I store my per-project setup scripts to source at the root of the project, in our case ~/gfx):<br /><pre class="brush: bash; gutter: false">$ cat ~/gfx/setup-env<br />PROJECT=~/gfx<br />export PATH=$PROJECT/install/bin:$PATH<br />export LD_LIBRARY_PATH=$PROJECT/install/lib:$LD_LIBRARY_PATH<br />export PKG_CONFIG_PATH=$PROJECT/install/lib/pkgconfig:$PKG_CONFIG_PATH<br />export ACLOCAL_FLAGS="-I $PROJECT/install/share/aclocal $ACLOCAL_FLAG"<br />$ source ~/gfx/setup-env</pre>Then it's time to compile libdrm, telling the <code>configure</code> script that we want to install it in in our prefix:<br /><pre class="brush: bash; gutter: false">$ cd ~/gfx/sources/libdrm<br />$ ./autogen.sh --prefix=/home/damien/gfx/install<br />$ make<br />$ make install</pre>Note that you don't need to run "sudo make install" since we'll be installing in our prefix directory that is writeable by the current user.<br /><br />Now it's time to compile i-g-t:<br /><pre class="brush: bash; gutter: false">$ cd ~/gfx/sources/intel-gpu-tools<br />$ ./autogen.sh --prefix=/home/damien/gfx/install<br />$ make<br />$ make install</pre>The configure script may complain about dependencies (eg. cairo, SWIG,...). Different ways to solve those:<br /><ul style="text-align: left;"><li>For dependencies not directly linked with the graphics stack (like SWIG), it's recommended to use the development package provided by the distribution</li><li>For old enough dependencies that don't change very often (like cairo) you can use the distribution development package or compile them in your prefix</li><li>For dependencies more recent than your distribution ones, you need to install them in the chosen prefix.</li></ul></div>
]]></content>
		</item>
		
		<item>
			<title>git commit --fixup and git rebase -i --autosquash</title>
			<link>https://dlespiau.github.io/posts/2014-01-20-git-commit---fixup-and-git-rebase--i---autosquash/</link>
			<pubDate>Mon, 20 Jan 2014 11:18:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2014-01-20-git-commit---fixup-and-git-rebase--i---autosquash/</guid>
			<description>It&amp;rsquo;s not unusual that I need to fix previous commits up when working on a branch or in the review phase. Until now I used a regular commit with some special marker to remember which commit to squash it with and then git rebase -i to reorder the patches and squash the fixup commits with their corresponding &amp;ldquo;parent&amp;rdquo; commits.
Turns out, git can handle quite a few of those manual manipulations for you.</description>
			<content type="html"><![CDATA[<p>It&rsquo;s not unusual that I need to fix previous commits up when working  on a branch or in the review phase. Until now I used a regular commit with some special marker to remember which commit to squash it with and then git rebase -i to reorder the patches and squash the fixup commits with their corresponding &ldquo;parent&rdquo; commits.<br /><br />Turns out, git can handle quite a few of those manual manipulations for you. <code>git commit &ndash;fixup &lt;commit&gt;</code> allows you to commit work, marking it as a fixup of a previous commit. <code>git rebase -i &ndash;autosquash</code> will then present the usual <code>git rebase -i</code> screen but with the fixup commits moved just after their parents and ready to be squashed without any extra manipulation.<br /><br />For instance, I had a couple of changes to a commit buried 100 patches away from <code>HEAD</code> (yes, a big topic branch!):<br /><pre class="brush: diff; gutter: false">$ git diff<br />diff &ndash;git a/drivers/gpu/drm/i915/intel_display.c b/drivers/gpu/drm/i915/intel_display.c<br />index 29f3813..08ea851 100644<br />&mdash; a/drivers/gpu/drm/i915/intel_display.c<br />+++ b/drivers/gpu/drm/i915/intel_display.c<br />@@ -2695,6 +2695,11 @@ static void skylake_update_primary_plane(struct drm_crtc <em>crtc,<br /><br />        intel_fb = to_intel_framebuffer(fb);<br />        obj = intel_fb-&gt;obj;<br />+<br />+       /</em><br />+        * The stride is expressed either as a multiple of 64 bytes chunks for<br />+        * linear buffers or in number of tiles for tiled buffers.<br />+        */<br />        switch (obj-&gt;tiling_mode) {<br />        case I915_TILING_NONE:<br />               stride = fb-&gt;pitches[0] &gt;&gt; 6;<br />@@ -2707,7 +2712,6 @@ static void skylake_update_primary_plane(struct drm_crtc *crtc,<br />BUG();<br />}<br /><br />-       plane_ctl &amp;= ~PLANE_CTL_TRICKLE_FEED_DISABLE;<br />        plane_ctl |= PLANE_CTL_PLANE_GAMMA_DISABLE;<br /><br />        I915_WRITE(PLANE_CTL(pipe, 0), plane_ctl);</pre>And I wanted to squash those changes with commit <code>2021785</code><br /><pre class="brush: bash; gutter: false">$ git commit -a &ndash;fixup 2021785<br /></pre>git will then go ahead and create a new commit with the subject taken from the referenced commit and prefixed with <code>fixup!</code><br /><pre class="brush: bash; gutter: false">commit d2d278ffbe87d232369b028d0c9ee9e6ecd0ba20<br />Author: Damien Lespiau &lt;damien.lespiau@intel.com&gt;<br />Date:   Sat Sep 20 11:09:15 2014 +0100<br /><br />fixup! drm/i915/skl: Implement thew new update_plane() for primary planes</pre>Then when using the interactive rebase with autosquash:<br /><pre class="brush: bash; gutter: false">$ git rebase -i &ndash;autosquash drm-intel/drm-intel-nightly<br /></pre>The fixup will be next after the reference commit<br /><pre class="brush: bash; gutter: false">pick 2021785 drm/i915/skl: Implement thew new update_plane() for primary planes<br />fixup d2d278ff fixup! drm/i915/skl: Implement thew new update_plane() for primary planes</pre>validating the proposed change (by in my case leaving vim) will squash the fixup commits. Definitely what I&rsquo;ll be using from now on!<br /><br />Oh, and there&rsquo;s a config option to have git rebase automatically autosquash if there are some fixup commits:<br /><pre class="brush: bash; gutter: false">$ git config &ndash;global rebase.autosquash true</pre></p>
]]></content>
		</item>
		
		<item>
			<title>A git pre-commit hook to check the year of copyright notices</title>
			<link>https://dlespiau.github.io/posts/2013-01-13-a-git-pre-commit-hook-to-check-the-year-of-copyright-notices/</link>
			<pubDate>Sun, 13 Jan 2013 21:39:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2013-01-13-a-git-pre-commit-hook-to-check-the-year-of-copyright-notices/</guid>
			<description>Like every year, touching a source file means you also need to update the year of the copyright notice you should have at the top of the file. I always end up forgetting about them, this is where a git pre-commit hook would be ultra-useful, so I wrote one:#
# Check if copyright statements include the current year
#
files=git diff --cached --name-only
year=date +&amp;amp;quot;%Y&amp;amp;quot;
for f in $files; do</description>
			<content type="html"><![CDATA[<p>Like every year, touching a source file means you also need to update the year of the copyright notice you should have at the top of the file. I always end up forgetting about them, this is where a git pre-commit hook would be ultra-useful, so I wrote one:<pre class="brush: bash; gutter: true; first-line: 1; highlight: []; html-script: false">#<br /># Check if copyright statements include the current year<br />#<br />files=<code>git diff --cached --name-only</code><br />year=<code>date +&amp;quot;%Y&amp;quot;</code><br /><br />for f in $files; do<br />    head -10 $f | grep -i copyright 2&gt;&amp;1 1&gt;/dev/null || continue<br /><br />    if ! grep -i -e &quot;copyright.*$year&quot; $f 2&gt;&amp;1 1&gt;/dev/null; then<br />        missing_copyright_files=&quot;$missing_copyright_files $f&quot;<br />    fi<br />done<br /><br />if [ -n &quot;$missing_copyright_files&quot; ]; then<br />    echo &quot;$year is missing in the copyright notice of the following files:&quot;<br />    for f in $missing_copyright_files; do<br />        echo &quot;    $f&quot;<br />    done <br />    exit 1<br />fi</pre>Hope this helps!</p>
]]></content>
		</item>
		
		<item>
			<title>Working on more than one line with sed&#39;s &#39;N&#39; command</title>
			<link>https://dlespiau.github.io/posts/2013-01-03-working-on-more-than-one-line-with-seds-n-command/</link>
			<pubDate>Thu, 03 Jan 2013 14:24:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2013-01-03-working-on-more-than-one-line-with-seds-n-command/</guid>
			<description>Yesterday I was asked to help solving a small sed problem. Considering that file (don&#39;t look too closely on the engineering of the defined elements):
&amp;lt;root&amp;gt;
&amp;lt;key&amp;gt;key0&amp;lt;/key&amp;gt;
&amp;lt;string&amp;gt;value0&amp;lt;/string&amp;gt;
&amp;lt;key&amp;gt;key1&amp;lt;/key&amp;gt;
&amp;lt;string&amp;gt;value1&amp;lt;/string&amp;gt;
&amp;lt;key&amp;gt;key2&amp;lt;/key&amp;gt;
&amp;lt;string&amp;gt;value2&amp;lt;/string&amp;gt;
&amp;lt;/root&amp;gt;The problem was: How to change value1 to VALUE!. The problem here is that you can&#39;t blindly execute a s command matching &amp;lt;string&amp;gt;.*&amp;lt;/string&amp;gt;.
Sed maintains a buffer called the &#34;pattern space&#34; and processes commands on this buffer. From the GNU sed manual:</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on">Yesterday I was asked to help solving a small <code>sed</code> problem. Considering that file (don't look too closely on the engineering of the defined elements):<br /><div><pre class="brush: text; gutter: true">&lt;root&gt;<br />  &lt;key&gt;key0&lt;/key&gt;<br />  &lt;string&gt;value0&lt;/string&gt;<br />  &lt;key&gt;key1&lt;/key&gt;<br />  &lt;string&gt;value1&lt;/string&gt;<br />  &lt;key&gt;key2&lt;/key&gt;<br />  &lt;string&gt;value2&lt;/string&gt;<br />&lt;/root&gt;</pre><div>The problem was: How to change <code>value1</code> to <code>VALUE!</code>. The problem here is that you can't blindly execute a <code>s</code> command matching<code> &lt;string&gt;.*&lt;/string&gt;</code>.<br />Sed maintains a buffer called the "pattern space" and processes commands on this buffer. From the GNU sed manual:<br /><blockquote>sed operates by performing the following cycle on each line of input: first, sed reads one line from the input stream, removes any trailing newline, and places it in the pattern space. Then commands are executed; each command can have an address associated to it: <a href="http://www.gnu.org/software/sed/manual/sed.html#Addresses" title="sed addresses">addresses</a> are a kind of condition code, and a command is only executed if the condition is verified before the command is to be executed.<br /><br />When the end of the script [(list of sed commands)] is reached, unless the -n option is in use, the contents of pattern space are printed out to the output stream, adding back the trailing newline if it was removed.3 Then the next cycle starts for the next input line.</blockquote>So the idea is to first, use a <code>/pattern/</code> address to select the the right &lt;key&gt; line, append the next line to the pattern space (with the <a href="http://www.gnu.org/software/sed/manual/sed.html#Other-Commands">N command</a>) and finally run a s command on the buffer now containing both lines:<br /><pre class="brush: text; gutter: true">&lt;key&gt;key1&lt;/key&gt;<br />  &lt;string&gt;value1&lt;/string&gt;</pre>And so we end up with:<br /><pre class="brush: text; gutter: true">$ cat input <br />&lt;root&gt;<br />  &lt;key&gt;key0&lt;/key&gt;<br />  &lt;string&gt;value0&lt;/string&gt;<br />  &lt;key&gt;key1&lt;/key&gt;<br />  &lt;string&gt;value1&lt;/string&gt;<br />  &lt;key&gt;key2&lt;/key&gt;<br />  &lt;string&gt;value2&lt;/string&gt;<br />&lt;/root&gt;<br />$ sed -e '/&lt;key&gt;key1&lt;\/key&gt;/{N;s#&lt;string&gt;.*&lt;\/string&gt;#&lt;string&gt;VALUE!&lt;\/string#;}' &lt; input <br />&lt;root&gt;<br />  &lt;key&gt;key0&lt;/key&gt;<br />  &lt;string&gt;value0&lt;/string&gt;<br />  &lt;key&gt;key1&lt;/key&gt;<br />  &lt;string&gt;VALUE!&lt;/string<br />  &lt;key&gt;key2&lt;/key&gt;<br />  &lt;string&gt;value2&lt;/string&gt;<br />&lt;/root&gt;</pre></div></div></div>
]]></content>
		</item>
		
		<item>
			<title>HDMI stereo 3D &amp; KMS</title>
			<link>https://dlespiau.github.io/posts/2013-01-02-hdmi-stereo-3d--kms/</link>
			<pubDate>Wed, 02 Jan 2013 19:38:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2013-01-02-hdmi-stereo-3d--kms/</guid>
			<description>If everything goes according to plan, KMS in linux 3.13 should have stereo 3D support. Should one be interested in scanning out a stereo frame buffer to a 3D capable HDMI sink, here&#39;s a rough description of how those modes are exposed to user space and how to use them.
A reader not well acquainted with the DRM sub-system and its mode setting API (Aka Kernel Mode Setting, KMS) could start by watching the first part of Laurent Pinchart&#39;s Anatomy of an Embedded KMS Driver or read David Herrmann&#39;s heavily documented mode setting example code.</description>
			<content type="html"><![CDATA[<div dir="ltr" style="text-align: left;" trbidi="on">If everything goes according to plan, KMS in linux 3.13 should have stereo 3D support. Should one be interested in scanning out a stereo frame buffer to a 3D capable HDMI sink, here's a rough description of how those modes are exposed to user space and how to use them.<br /><br />A reader not well acquainted with the DRM sub-system and its mode setting API (Aka Kernel Mode Setting, KMS) could start by watching the first part of Laurent Pinchart's<em> <a href="http://www.youtube.com/watch?v=Ja8fM7rTae4" target="_blank">Anatomy of an Embedded KMS Driver</a></em> or read David Herrmann's heavily documented <a href="https://github.com/dvdhrm/docs/blob/master/drm-howto/modeset.c" target="_blank" title="Mode setting example">mode setting example</a> code.<br /><br />Stereo modes work by sending a left eye and right eye picture per frame to the monitor. It's then up to the monitor to use those 2 pictures to display a 3D frame and the technology there varies.<br /><br />There are different ways to organise the 2 pictures inside a bigger frame buffer. For HDMI, those layouts are described in the HDMI 1.4 specification. Provided you give them your contact details, it's possible to download the stereo 3D part of the HDMI 1.4 spec from <a href="http://www.hdmi.org/manufacturer/specification.aspx" target="_blank" title="HDMI stereo 3D extraction">hdmi.org</a>.<br /><br />As one inevitably knows, modes supported by a monitor can be retrieved out of the KMS connector object in the form of <code>drmModeModeInfo</code> structures (when using <a href="http://cgit.freedesktop.org/mesa/drm" target="_blank" title="libdrm git repository">libdrm</a>, it's also possible to write your own wrappers around the KMS ioctls, should you want to):<br /><pre class="brush: c; gutter: true; first-line: 1; highlight: []; html-script: false ">typedef struct _drmModeModeInfo {<br />        uint32_t clock;<br />        uint16_t hdisplay, hsync_start, hsync_end, htotal, hskew;<br />        uint16_t vdisplay, vsync_start, vsync_end, vtotal, vscan;<br /><br />        uint32_t vrefresh;<br /><br />        uint32_t flags;<br />        uint32_t type;<br />        char name[...];<br />} drmModeModeInfo, *drmModeModeInfoPtr;</pre>To keep existing software blissfully unaware of those modes, a DRM client interested in having stereo modes listed starts by telling the kernel to expose them:<br /><pre class="brush: c; gutter: true; first-line: 1; highlight: []; html-script: false ">drmSetClientCap(drm_fd, DRM_CLIENT_CAP_STEREO_3D, 1);</pre>Stereo modes use the <code>flags</code> field to advertise which layout the mode requires:<br /><pre class="brush: c; gutter: true; first-line: 1; highlight: []; html-script: false ">uint32_t layout = mode-&gt;flags &amp; DRM_MODE_FLAG_3D_MASK;</pre>This will give you a non zero value when the mode is a stereo mode, value among:<br /><pre class="brush: c; gutter: true; first-line: 1; highlight: []; html-script: false ">DRM_MODE_FLAG_3D_FRAME_PACKING<br />DRM_MODE_FLAG_3D_FIELD_ALTERNATIVE<br />DRM_MODE_FLAG_3D_LINE_ALTERNATIVE<br />DRM_MODE_FLAG_3D_SIDE_BY_SIDE_FULL<br />DRM_MODE_FLAG_3D_L_DEPTH<br />DRM_MODE_FLAG_3D_L_DEPTH_GFX_GFX_DEPTH<br />DRM_MODE_FLAG_3D_TOP_AND_BOTTOM<br />DRM_MODE_FLAG_3D_SIDE_BY_SIDE_HALF</pre>User space is then responsible for choosing which stereo mode to use and to prepare a buffer that matches the size and left/right placement requirements of that layout. For instance, when choosing<em> Side by Side (half)</em>, the frame buffer is the same size as its 2D equivalent (that is <code>hdisplay</code> x <code>vdisplay</code>) with the left and right images sub-sampled by 2 horizontally:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-Neo5kpMxAvk/VrY4aNWx-gI/AAAAAAAAAZ0/OWoJ3WdFppI/s1600/sbsh.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="https://1.bp.blogspot.com/-Neo5kpMxAvk/VrY4aNWx-gI/AAAAAAAAAZ0/OWoJ3WdFppI/s1600/sbsh.jpg" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-size: small; text-align: left;">Side by Side (half)</span></td></tr></tbody></table><br />Other modes need a bigger buffer than <code>hdisplay</code> x <code>vdisplay</code>. This is the case with <em>frame packing</em>, where each eye has the the full 2D resolution, separated by the number of vblank lines:<br /><br /><div class="separator" style="clear: both; text-align: center;"></div><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://3.bp.blogspot.com/-GPJPDMeYTcc/VrY6bGACavI/AAAAAAAAAaE/iZHl1dH9eLE/s1600/fp.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="https://3.bp.blogspot.com/-GPJPDMeYTcc/VrY6bGACavI/AAAAAAAAAaE/iZHl1dH9eLE/s1600/fp.jpg" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Fame Packing</td></tr></tbody></table><br />Of course, anything can be used to draw into the stereo frame buffer, including OpenGL. Further work should enable Mesa to directly render into such buffers, say with the EGL/gbm winsys for a wayland compositor to use.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-ARZ7hQsd5uo/VrY63aGegQI/AAAAAAAAAaI/UIqA8bq9u4M/s1600/PS3_3D2-891x1024.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://1.bp.blogspot.com/-ARZ7hQsd5uo/VrY63aGegQI/AAAAAAAAAaI/UIqA8bq9u4M/s400/PS3_3D2-891x1024.jpg" width="347" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Wipe Out using Frame Packing on the PS3</td></tr></tbody></table><br />Behind the scene, the kernel's job is to parse the EDID to discover which stereo modes the HDMI sink supports and, once user-space instructs to use a stereo mode, to send infoframes (metadata sent during the vblank interval) with the information about which 3D mode is being sent.<br /><br />A good place to start for anyone wanting to use this API is <code><a href="http://cgit.freedesktop.org/xorg/app/intel-gpu-tools/tree/tests/testdisplay.c" target="_blank">testdisplay</a></code>, part of the <a href="http://cgit.freedesktop.org/xorg/app/intel-gpu-tools/" target="_blank">Intel GPU tools</a> test suite. <code>testdisplay</code> can list the available modes with:<br /><pre class="brush: text; gutter: true">$ sudo ./tests/testdisplay -3 -i<br />[...]<br />name refresh (Hz) hdisp hss hse htot vdisp vss vse vtot flags type clock<br />[0]  1920x1080 60 1920 2008 2052 2200 1080 1084 1089 1125 0x5 0x48 148500<br />[1]  1920x1080 60 1920 2008 2052 2200 1080 1084 1089 1125 0x5 0x40 148352<br />[2]  1920x1080i 60 1920 2008 2052 2200 1080 1084 1094 1125 0x15 0x40 74250<br />[3]  1920x1080i 60 1920 2008 2052 2200 1080 1084 1094 1125 0x20015 0x40 74250 (3D:SBSH)<br />[4]  1920x1080i 60 1920 2008 2052 2200 1080 1084 1094 1125 0x15 0x40 74176<br />[5]  1920x1080i 60 1920 2008 2052 2200 1080 1084 1094 1125 0x20015 0x40 74176 (3D:SBSH)<br />[6]  1920x1080 50 1920 2448 2492 2640 1080 1084 1089 1125 0x5 0x40 148500<br />[7]  1920x1080i 50 1920 2448 2492 2640 1080 1084 1094 1125 0x15 0x40 74250<br />[8]  1920x1080i 50 1920 2448 2492 2640 1080 1084 1094 1125 0x20015 0x40 74250 (3D:SBSH)<br />[9]  1920x1080 24 1920 2558 2602 2750 1080 1084 1089 1125 0x5 0x40 74250<br />[10]  1920x1080 24 1920 2558 2602 2750 1080 1084 1089 1125 0x1c005 0x40 74250 (3D:TB)<br />[11]  1920x1080 24 1920 2558 2602 2750 1080 1084 1089 1125 0x4005 0x40 74250 (3D:FP)<br />[...]</pre>To test a specific mode:<br /><pre class="brush: text; gutter: true">$ sudo ./tests/testdisplay -3 -o 17,10<br />1920x1080 24 1920 2558 2602 2750 1080 1084 1089 1125 0x1c005 0x40 74250 (3D:TB)</pre>To cycle through all the supported stereo modes:<br /><pre class="brush: text; gutter: true">$ sudo ./tests/testdisplay -3</pre><code>testdisplay</code> uses cairo to compose the final frame buffer from two separate left and right test images.</div>
]]></content>
		</item>
		
		<item>
			<title>Extracting part of files with sed</title>
			<link>https://dlespiau.github.io/posts/2012-01-10-extracting-part-of-files-with-sed/</link>
			<pubDate>Tue, 10 Jan 2012 14:34:00 +0000</pubDate>
			
			<guid>https://dlespiau.github.io/posts/2012-01-10-extracting-part-of-files-with-sed/</guid>
			<description>For reference for my future self, a few handy sed commands. Let&amp;rsquo;s consider this file:$ cat test-sed
First line
Second line
&amp;ndash;
Another line
Last lineWe can extract the lines from the start of the file to the marker by deleting the rest:$ sed &amp;#039;/&amp;ndash;/,$d&amp;#039; test-sed First line
Second linea,b is the range the command, here d(elete), applies to. a and b can be, among others, line numbers, regular expressions or $ for end of the file.</description>
			<content type="html"><![CDATA[<p>For reference for my future self, a few handy sed commands. Let&rsquo;s consider this file:<pre class="brush: text; gutter: true">$ cat test-sed<br />First line<br />Second line<br />&ndash;<br />Another line<br />Last line</pre>We can extract the lines from the start of the file to the marker by deleting the rest:<pre class="brush: text; gutter: true">$ sed &#039;/&ndash;/,$d&#039; test-sed <br />First line<br />Second line</pre><code>a,b</code> is the range the command, here <code>d(elete)</code>, applies to. <code>a</code> and <code>b</code> can be, among others, line numbers, regular expressions or <code>$</code> for end of the file. We can also extract the lines from the marker to the end of the file with:<pre class="brush: text; gutter: true">$ sed -n &#039;/&ndash;/,$p&#039; test-sed <br />&ndash;<br />Another line<br />Last line</pre>This one is slightly more complicated. By default sed spits all the lines it receives as input, <code>&rsquo;-n&rsquo;</code> is there to tell sed not to do that. The rest of the expression is to <code>p(rint)</code> the lines between <code>&ndash;</code> and the end of the file.<br />That&rsquo;s all folks!</p>
]]></content>
		</item>
		
	</channel>
</rss>
